&&&& RUNNING TensorRT.trtexec [TensorRT v8600] # trtexec --onnx=resnet50_bs_dynamic.onnx --saveEngine=demo.engine --minShapes=input:1x3x224x224 --maxShapes=input:64x3x224x224 --optShapes=input:64x3x224x224
[08/20/2023-10:13:56] [I] === Model Options ===
[08/20/2023-10:13:56] [I] Format: ONNX
[08/20/2023-10:13:56] [I] Model: resnet50_bs_dynamic.onnx
[08/20/2023-10:13:56] [I] Output:
[08/20/2023-10:13:56] [I] === Build Options ===
[08/20/2023-10:13:56] [I] Max batch: explicit batch
[08/20/2023-10:13:56] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[08/20/2023-10:13:56] [I] minTiming: 1
[08/20/2023-10:13:56] [I] avgTiming: 8
[08/20/2023-10:13:56] [I] Precision: FP32
[08/20/2023-10:13:56] [I] LayerPrecisions: 
[08/20/2023-10:13:56] [I] Layer Device Types: 
[08/20/2023-10:13:56] [I] Calibration: 
[08/20/2023-10:13:56] [I] Refit: Disabled
[08/20/2023-10:13:56] [I] Version Compatible: Disabled
[08/20/2023-10:13:56] [I] TensorRT runtime: full
[08/20/2023-10:13:56] [I] Lean DLL Path: 
[08/20/2023-10:13:56] [I] Tempfile Controls: { in_memory: allow, temporary: allow }
[08/20/2023-10:13:56] [I] Exclude Lean Runtime: Disabled
[08/20/2023-10:13:56] [I] Sparsity: Disabled
[08/20/2023-10:13:56] [I] Safe mode: Disabled
[08/20/2023-10:13:56] [I] DirectIO mode: Disabled
[08/20/2023-10:13:56] [I] Restricted mode: Disabled
[08/20/2023-10:13:56] [I] Skip inference: Disabled
[08/20/2023-10:13:56] [I] Save engine: demo.engine
[08/20/2023-10:13:56] [I] Load engine: 
[08/20/2023-10:13:56] [I] Profiling verbosity: 0
[08/20/2023-10:13:56] [I] Tactic sources: Using default tactic sources
[08/20/2023-10:13:56] [I] timingCacheMode: local
[08/20/2023-10:13:56] [I] timingCacheFile: 
[08/20/2023-10:13:56] [I] Heuristic: Disabled
[08/20/2023-10:13:56] [I] Preview Features: Use default preview flags.
[08/20/2023-10:13:56] [I] MaxAuxStreams: -1
[08/20/2023-10:13:56] [I] BuilderOptimizationLevel: 3
[08/20/2023-10:13:56] [I] Input(s)s format: fp32:CHW
[08/20/2023-10:13:56] [I] Output(s)s format: fp32:CHW
[08/20/2023-10:13:56] [I] Input build shape: input=1x3x224x224+64x3x224x224+64x3x224x224
[08/20/2023-10:13:56] [I] Input calibration shapes: model
[08/20/2023-10:13:56] [I] === System Options ===
[08/20/2023-10:13:56] [I] Device: 0
[08/20/2023-10:13:56] [I] DLACore: 
[08/20/2023-10:13:56] [I] Plugins:
[08/20/2023-10:13:56] [I] setPluginsToSerialize:
[08/20/2023-10:13:56] [I] dynamicPlugins:
[08/20/2023-10:13:56] [I] ignoreParsedPluginLibs: 0
[08/20/2023-10:13:56] [I] 
[08/20/2023-10:13:56] [I] === Inference Options ===
[08/20/2023-10:13:56] [I] Batch: Explicit
[08/20/2023-10:13:56] [I] Input inference shape: input=64x3x224x224
[08/20/2023-10:13:56] [I] Iterations: 10
[08/20/2023-10:13:56] [I] Duration: 3s (+ 200ms warm up)
[08/20/2023-10:13:56] [I] Sleep time: 0ms
[08/20/2023-10:13:56] [I] Idle time: 0ms
[08/20/2023-10:13:56] [I] Inference Streams: 1
[08/20/2023-10:13:56] [I] ExposeDMA: Disabled
[08/20/2023-10:13:56] [I] Data transfers: Enabled
[08/20/2023-10:13:56] [I] Spin-wait: Disabled
[08/20/2023-10:13:56] [I] Multithreading: Disabled
[08/20/2023-10:13:56] [I] CUDA Graph: Disabled
[08/20/2023-10:13:56] [I] Separate profiling: Disabled
[08/20/2023-10:13:56] [I] Time Deserialize: Disabled
[08/20/2023-10:13:56] [I] Time Refit: Disabled
[08/20/2023-10:13:56] [I] NVTX verbosity: 0
[08/20/2023-10:13:56] [I] Persistent Cache Ratio: 0
[08/20/2023-10:13:56] [I] Inputs:
[08/20/2023-10:13:56] [I] === Reporting Options ===
[08/20/2023-10:13:56] [I] Verbose: Disabled
[08/20/2023-10:13:56] [I] Averages: 10 inferences
[08/20/2023-10:13:56] [I] Percentiles: 90,95,99
[08/20/2023-10:13:56] [I] Dump refittable layers:Disabled
[08/20/2023-10:13:56] [I] Dump output: Disabled
[08/20/2023-10:13:56] [I] Profile: Disabled
[08/20/2023-10:13:56] [I] Export timing to JSON file: 
[08/20/2023-10:13:56] [I] Export output to JSON file: 
[08/20/2023-10:13:56] [I] Export profile to JSON file: 
[08/20/2023-10:13:56] [I] 
[08/20/2023-10:13:56] [I] === Device Information ===
[08/20/2023-10:13:56] [I] Selected Device: NVIDIA GeForce RTX 3060 Laptop GPU
[08/20/2023-10:13:56] [I] Compute Capability: 8.6
[08/20/2023-10:13:56] [I] SMs: 30
[08/20/2023-10:13:56] [I] Device Global Memory: 6143 MiB
[08/20/2023-10:13:56] [I] Shared Memory per SM: 100 KiB
[08/20/2023-10:13:56] [I] Memory Bus Width: 192 bits (ECC disabled)
[08/20/2023-10:13:56] [I] Application Compute Clock Rate: 1.702 GHz
[08/20/2023-10:13:56] [I] Application Memory Clock Rate: 7.001 GHz
[08/20/2023-10:13:56] [I] 
[08/20/2023-10:13:56] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.
[08/20/2023-10:13:56] [I] 
[08/20/2023-10:13:56] [I] TensorRT version: 8.6.0
[08/20/2023-10:13:56] [I] Loading standard plugins
[08/20/2023-10:13:56] [I] [TRT] [MemUsageChange] Init CUDA: CPU +329, GPU +0, now: CPU 17572, GPU 1092 (MiB)
[08/20/2023-10:14:01] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1220, GPU +262, now: CPU 19906, GPU 1354 (MiB)
[08/20/2023-10:14:01] [I] Start parsing network model.
[08/20/2023-10:14:01] [I] [TRT] ----------------------------------------------------------------
[08/20/2023-10:14:01] [I] [TRT] Input filename:   resnet50_bs_dynamic.onnx
[08/20/2023-10:14:01] [I] [TRT] ONNX IR version:  0.0.7
[08/20/2023-10:14:01] [I] [TRT] Opset version:    13
[08/20/2023-10:14:01] [I] [TRT] Producer name:    pytorch
[08/20/2023-10:14:01] [I] [TRT] Producer version: 1.12.0
[08/20/2023-10:14:01] [I] [TRT] Domain:           
[08/20/2023-10:14:01] [I] [TRT] Model version:    0
[08/20/2023-10:14:01] [I] [TRT] Doc string:       
[08/20/2023-10:14:01] [I] [TRT] ----------------------------------------------------------------
[08/20/2023-10:14:01] [I] Finished parsing network model. Parse time: 0.129821
[08/20/2023-10:14:01] [I] [TRT] Graph optimization time: 0.014168 seconds.
[08/20/2023-10:14:01] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[08/20/2023-10:14:49] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[08/20/2023-10:14:49] [I] [TRT] Total Host Persistent Memory: 358448
[08/20/2023-10:14:49] [I] [TRT] Total Device Persistent Memory: 0
[08/20/2023-10:14:49] [I] [TRT] Total Scratch Memory: 25693696
[08/20/2023-10:14:49] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 9 MiB, GPU 451 MiB
[08/20/2023-10:14:49] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 82 steps to complete.
[08/20/2023-10:14:49] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 1.6041ms to assign 6 blocks to 82 nodes requiring 526648320 bytes.
[08/20/2023-10:14:49] [I] [TRT] Total Activation Memory: 526647296
[08/20/2023-10:14:49] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +98, now: CPU 0, GPU 98 (MiB)
[08/20/2023-10:14:49] [I] Engine built in 53.8518 sec.
[08/20/2023-10:14:50] [I] [TRT] Loaded engine size: 99 MiB
[08/20/2023-10:14:50] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +97, now: CPU 0, GPU 97 (MiB)
[08/20/2023-10:14:50] [I] Engine deserialized in 0.0201847 sec.
[08/20/2023-10:14:50] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +502, now: CPU 0, GPU 599 (MiB)
[08/20/2023-10:14:50] [I] Setting persistentCacheLimit to 0 bytes.
[08/20/2023-10:14:50] [I] Using random values for input input
[08/20/2023-10:14:50] [I] Created input binding for input with dimensions 64x3x224x224
[08/20/2023-10:14:50] [I] Using random values for output output
[08/20/2023-10:14:50] [I] Created output binding for output with dimensions 64x1000
[08/20/2023-10:14:50] [I] Starting inference
[08/20/2023-10:14:53] [I] Warmup completed 4 queries over 200 ms
[08/20/2023-10:14:53] [I] Timing trace has 55 queries over 3.08539 s
[08/20/2023-10:14:53] [I] 
[08/20/2023-10:14:53] [I] === Trace details ===
[08/20/2023-10:14:53] [I] Trace averages of 10 runs:
[08/20/2023-10:14:53] [I] Average on 10 runs - GPU latency: 51.9265 ms - Host latency: 55.9616 ms (enqueue 0.605026 ms)
[08/20/2023-10:14:53] [I] Average on 10 runs - GPU latency: 51.9047 ms - Host latency: 55.9201 ms (enqueue 0.514777 ms)
[08/20/2023-10:14:53] [I] Average on 10 runs - GPU latency: 51.8668 ms - Host latency: 55.877 ms (enqueue 0.569067 ms)
[08/20/2023-10:14:53] [I] Average on 10 runs - GPU latency: 51.9147 ms - Host latency: 55.9761 ms (enqueue 0.548413 ms)
[08/20/2023-10:14:53] [I] Average on 10 runs - GPU latency: 51.9697 ms - Host latency: 56.0137 ms (enqueue 0.583057 ms)
[08/20/2023-10:14:53] [I] 
[08/20/2023-10:14:53] [I] === Performance summary ===
[08/20/2023-10:14:53] [I] Throughput: 17.8259 qps
[08/20/2023-10:14:53] [I] Latency: min = 55.5354 ms, max = 56.4409 ms, mean = 55.9566 ms, median = 55.9484 ms, percentile(90%) = 56.2191 ms, percentile(95%) = 56.353 ms, percentile(99%) = 56.4409 ms
[08/20/2023-10:14:53] [I] Enqueue Time: min = 0.424194 ms, max = 1.06592 ms, mean = 0.565612 ms, median = 0.519623 ms, percentile(90%) = 0.812744 ms, percentile(95%) = 0.939087 ms, percentile(99%) = 1.06592 ms
[08/20/2023-10:14:53] [I] H2D Latency: min = 3.8385 ms, max = 4.20703 ms, mean = 4.00451 ms, median = 3.99976 ms, percentile(90%) = 4.12494 ms, percentile(95%) = 4.13501 ms, percentile(99%) = 4.20703 ms
[08/20/2023-10:14:53] [I] GPU Compute Time: min = 51.5912 ms, max = 52.3245 ms, mean = 51.9197 ms, median = 51.9434 ms, percentile(90%) = 52.1295 ms, percentile(95%) = 52.1923 ms, percentile(99%) = 52.3245 ms
[08/20/2023-10:14:53] [I] D2H Latency: min = 0.0279541 ms, max = 0.0527344 ms, mean = 0.032428 ms, median = 0.0288086 ms, percentile(90%) = 0.045166 ms, percentile(95%) = 0.0491333 ms, percentile(99%) = 0.0527344 ms
[08/20/2023-10:14:53] [I] Total Host Walltime: 3.08539 s
[08/20/2023-10:14:53] [I] Total GPU Compute Time: 2.85558 s
[08/20/2023-10:14:53] [I] Explanations of the performance metrics are printed in the verbose logs.
[08/20/2023-10:14:53] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8600] # trtexec --onnx=resnet50_bs_dynamic.onnx --saveEngine=demo.engine --minShapes=input:1x3x224x224 --maxShapes=input:64x3x224x224 --optShapes=input:64x3x224x224
