&&&& RUNNING TensorRT.trtexec [TensorRT v8600] # C:\Program Files\TensorRT-8.6.0.12.Windows10.x86_64.cuda-11.8\TensorRT-8.6.0.12\bin\trtexec.exe --onnx=resnet50_bs_dynamic.onnx --saveEngine=demo.engine --minShapes=input:1x3x224x224 --maxShapes=input:128x3x224x224 --optShapes=input:128x3x224x224 --int8
[08/20/2023-11:20:27] [I] === Model Options ===
[08/20/2023-11:20:27] [I] Format: ONNX
[08/20/2023-11:20:27] [I] Model: resnet50_bs_dynamic.onnx
[08/20/2023-11:20:27] [I] Output:
[08/20/2023-11:20:27] [I] === Build Options ===
[08/20/2023-11:20:27] [I] Max batch: explicit batch
[08/20/2023-11:20:27] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[08/20/2023-11:20:27] [I] minTiming: 1
[08/20/2023-11:20:27] [I] avgTiming: 8
[08/20/2023-11:20:27] [I] Precision: FP32+INT8
[08/20/2023-11:20:27] [I] LayerPrecisions: 
[08/20/2023-11:20:27] [I] Layer Device Types: 
[08/20/2023-11:20:27] [I] Calibration: Dynamic
[08/20/2023-11:20:27] [I] Refit: Disabled
[08/20/2023-11:20:27] [I] Version Compatible: Disabled
[08/20/2023-11:20:27] [I] TensorRT runtime: full
[08/20/2023-11:20:27] [I] Lean DLL Path: 
[08/20/2023-11:20:27] [I] Tempfile Controls: { in_memory: allow, temporary: allow }
[08/20/2023-11:20:27] [I] Exclude Lean Runtime: Disabled
[08/20/2023-11:20:27] [I] Sparsity: Disabled
[08/20/2023-11:20:27] [I] Safe mode: Disabled
[08/20/2023-11:20:27] [I] DirectIO mode: Disabled
[08/20/2023-11:20:27] [I] Restricted mode: Disabled
[08/20/2023-11:20:27] [I] Skip inference: Disabled
[08/20/2023-11:20:27] [I] Save engine: demo.engine
[08/20/2023-11:20:27] [I] Load engine: 
[08/20/2023-11:20:27] [I] Profiling verbosity: 0
[08/20/2023-11:20:27] [I] Tactic sources: Using default tactic sources
[08/20/2023-11:20:27] [I] timingCacheMode: local
[08/20/2023-11:20:27] [I] timingCacheFile: 
[08/20/2023-11:20:27] [I] Heuristic: Disabled
[08/20/2023-11:20:27] [I] Preview Features: Use default preview flags.
[08/20/2023-11:20:27] [I] MaxAuxStreams: -1
[08/20/2023-11:20:27] [I] BuilderOptimizationLevel: 3
[08/20/2023-11:20:27] [I] Input(s)s format: fp32:CHW
[08/20/2023-11:20:27] [I] Output(s)s format: fp32:CHW
[08/20/2023-11:20:27] [I] Input build shape: input=1x3x224x224+128x3x224x224+128x3x224x224
[08/20/2023-11:20:27] [I] Input calibration shapes: model
[08/20/2023-11:20:27] [I] === System Options ===
[08/20/2023-11:20:27] [I] Device: 0
[08/20/2023-11:20:27] [I] DLACore: 
[08/20/2023-11:20:27] [I] Plugins:
[08/20/2023-11:20:27] [I] setPluginsToSerialize:
[08/20/2023-11:20:27] [I] dynamicPlugins:
[08/20/2023-11:20:27] [I] ignoreParsedPluginLibs: 0
[08/20/2023-11:20:27] [I] 
[08/20/2023-11:20:27] [I] === Inference Options ===
[08/20/2023-11:20:27] [I] Batch: Explicit
[08/20/2023-11:20:27] [I] Input inference shape: input=128x3x224x224
[08/20/2023-11:20:27] [I] Iterations: 10
[08/20/2023-11:20:27] [I] Duration: 3s (+ 200ms warm up)
[08/20/2023-11:20:27] [I] Sleep time: 0ms
[08/20/2023-11:20:27] [I] Idle time: 0ms
[08/20/2023-11:20:27] [I] Inference Streams: 1
[08/20/2023-11:20:27] [I] ExposeDMA: Disabled
[08/20/2023-11:20:27] [I] Data transfers: Enabled
[08/20/2023-11:20:27] [I] Spin-wait: Disabled
[08/20/2023-11:20:27] [I] Multithreading: Disabled
[08/20/2023-11:20:27] [I] CUDA Graph: Disabled
[08/20/2023-11:20:27] [I] Separate profiling: Disabled
[08/20/2023-11:20:27] [I] Time Deserialize: Disabled
[08/20/2023-11:20:27] [I] Time Refit: Disabled
[08/20/2023-11:20:27] [I] NVTX verbosity: 0
[08/20/2023-11:20:27] [I] Persistent Cache Ratio: 0
[08/20/2023-11:20:27] [I] Inputs:
[08/20/2023-11:20:27] [I] === Reporting Options ===
[08/20/2023-11:20:27] [I] Verbose: Disabled
[08/20/2023-11:20:27] [I] Averages: 10 inferences
[08/20/2023-11:20:27] [I] Percentiles: 90,95,99
[08/20/2023-11:20:27] [I] Dump refittable layers:Disabled
[08/20/2023-11:20:27] [I] Dump output: Disabled
[08/20/2023-11:20:27] [I] Profile: Disabled
[08/20/2023-11:20:27] [I] Export timing to JSON file: 
[08/20/2023-11:20:27] [I] Export output to JSON file: 
[08/20/2023-11:20:27] [I] Export profile to JSON file: 
[08/20/2023-11:20:27] [I] 
[08/20/2023-11:20:29] [I] === Device Information ===
[08/20/2023-11:20:29] [I] Selected Device: NVIDIA GeForce RTX 3060 Laptop GPU
[08/20/2023-11:20:29] [I] Compute Capability: 8.6
[08/20/2023-11:20:29] [I] SMs: 30
[08/20/2023-11:20:29] [I] Device Global Memory: 6143 MiB
[08/20/2023-11:20:29] [I] Shared Memory per SM: 100 KiB
[08/20/2023-11:20:29] [I] Memory Bus Width: 192 bits (ECC disabled)
[08/20/2023-11:20:29] [I] Application Compute Clock Rate: 1.702 GHz
[08/20/2023-11:20:29] [I] Application Memory Clock Rate: 7.001 GHz
[08/20/2023-11:20:29] [I] 
[08/20/2023-11:20:29] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.
[08/20/2023-11:20:29] [I] 
[08/20/2023-11:20:29] [I] TensorRT version: 8.6.0
[08/20/2023-11:20:29] [I] Loading standard plugins
[08/20/2023-11:20:29] [I] [TRT] [MemUsageChange] Init CUDA: CPU +314, GPU +0, now: CPU 16335, GPU 1092 (MiB)
[08/20/2023-11:20:34] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1214, GPU +262, now: CPU 18570, GPU 1354 (MiB)
[08/20/2023-11:20:34] [I] Start parsing network model.
[08/20/2023-11:20:34] [I] [TRT] ----------------------------------------------------------------
[08/20/2023-11:20:34] [I] [TRT] Input filename:   resnet50_bs_dynamic.onnx
[08/20/2023-11:20:34] [I] [TRT] ONNX IR version:  0.0.7
[08/20/2023-11:20:34] [I] [TRT] Opset version:    13
[08/20/2023-11:20:34] [I] [TRT] Producer name:    pytorch
[08/20/2023-11:20:34] [I] [TRT] Producer version: 1.12.0
[08/20/2023-11:20:34] [I] [TRT] Domain:           
[08/20/2023-11:20:34] [I] [TRT] Model version:    0
[08/20/2023-11:20:34] [I] [TRT] Doc string:       
[08/20/2023-11:20:34] [I] [TRT] ----------------------------------------------------------------
[08/20/2023-11:20:34] [I] Finished parsing network model. Parse time: 0.133646
[08/20/2023-11:20:34] [I] FP32 and INT8 precisions have been specified - more performance might be enabled by additionally specifying --fp16 or --best
[08/20/2023-11:20:34] [I] [TRT] Graph optimization time: 0.0147378 seconds.
[08/20/2023-11:20:34] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[08/20/2023-11:22:39] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[08/20/2023-11:22:40] [I] [TRT] Total Host Persistent Memory: 259840
[08/20/2023-11:22:40] [I] [TRT] Total Device Persistent Memory: 22528
[08/20/2023-11:22:40] [I] [TRT] Total Scratch Memory: 0
[08/20/2023-11:22:40] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 28 MiB, GPU 892 MiB
[08/20/2023-11:22:40] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 57 steps to complete.
[08/20/2023-11:22:40] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.9513ms to assign 3 blocks to 57 nodes requiring 256901120 bytes.
[08/20/2023-11:22:40] [I] [TRT] Total Activation Memory: 256901120
[08/20/2023-11:22:40] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +24, GPU +25, now: CPU 24, GPU 25 (MiB)
[08/20/2023-11:22:40] [I] Engine built in 131.421 sec.
[08/20/2023-11:22:40] [I] [TRT] Loaded engine size: 27 MiB
[08/20/2023-11:22:40] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +24, now: CPU 0, GPU 24 (MiB)
[08/20/2023-11:22:40] [I] Engine deserialized in 0.0144053 sec.
[08/20/2023-11:22:40] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +245, now: CPU 0, GPU 269 (MiB)
[08/20/2023-11:22:40] [I] Setting persistentCacheLimit to 0 bytes.
[08/20/2023-11:22:40] [I] Using random values for input input
[08/20/2023-11:22:41] [I] Created input binding for input with dimensions 128x3x224x224
[08/20/2023-11:22:41] [I] Using random values for output output
[08/20/2023-11:22:41] [I] Created output binding for output with dimensions 128x1000
[08/20/2023-11:22:41] [I] Starting inference
[08/20/2023-11:22:44] [I] Warmup completed 4 queries over 200 ms
[08/20/2023-11:22:44] [I] Timing trace has 125 queries over 3.06659 s
[08/20/2023-11:22:44] [I] 
[08/20/2023-11:22:44] [I] === Trace details ===
[08/20/2023-11:22:44] [I] Trace averages of 10 runs:
[08/20/2023-11:22:44] [I] Average on 10 runs - GPU latency: 16.7703 ms - Host latency: 25.2286 ms (enqueue 0.619527 ms)
[08/20/2023-11:22:44] [I] Average on 10 runs - GPU latency: 16.353 ms - Host latency: 24.3007 ms (enqueue 0.504004 ms)
[08/20/2023-11:22:44] [I] Average on 10 runs - GPU latency: 16.4122 ms - Host latency: 24.4638 ms (enqueue 0.571478 ms)
[08/20/2023-11:22:44] [I] Average on 10 runs - GPU latency: 16.3887 ms - Host latency: 24.4935 ms (enqueue 0.516724 ms)
[08/20/2023-11:22:44] [I] Average on 10 runs - GPU latency: 16.4183 ms - Host latency: 24.3842 ms (enqueue 0.520789 ms)
[08/20/2023-11:22:44] [I] Average on 10 runs - GPU latency: 16.4458 ms - Host latency: 24.2209 ms (enqueue 0.620789 ms)
[08/20/2023-11:22:44] [I] Average on 10 runs - GPU latency: 16.4423 ms - Host latency: 24.2766 ms (enqueue 0.629138 ms)
[08/20/2023-11:22:44] [I] Average on 10 runs - GPU latency: 16.4171 ms - Host latency: 24.2226 ms (enqueue 0.472485 ms)
[08/20/2023-11:22:44] [I] Average on 10 runs - GPU latency: 16.4396 ms - Host latency: 24.4055 ms (enqueue 0.511304 ms)
[08/20/2023-11:22:44] [I] Average on 10 runs - GPU latency: 16.4725 ms - Host latency: 24.2712 ms (enqueue 0.511182 ms)
[08/20/2023-11:22:44] [I] Average on 10 runs - GPU latency: 16.4719 ms - Host latency: 24.264 ms (enqueue 0.452148 ms)
[08/20/2023-11:22:44] [I] Average on 10 runs - GPU latency: 16.4026 ms - Host latency: 24.4195 ms (enqueue 0.538257 ms)
[08/20/2023-11:22:44] [I] 
[08/20/2023-11:22:44] [I] === Performance summary ===
[08/20/2023-11:22:44] [I] Throughput: 40.7618 qps
[08/20/2023-11:22:44] [I] Latency: min = 23.7621 ms, max = 25.8261 ms, mean = 24.4161 ms, median = 24.3384 ms, percentile(90%) = 24.916 ms, percentile(95%) = 25.1554 ms, percentile(99%) = 25.7939 ms
[08/20/2023-11:22:44] [I] Enqueue Time: min = 0.321045 ms, max = 1.22607 ms, mean = 0.539149 ms, median = 0.494995 ms, percentile(90%) = 0.765137 ms, percentile(95%) = 0.850998 ms, percentile(99%) = 1.09644 ms
[08/20/2023-11:22:44] [I] H2D Latency: min = 7.44739 ms, max = 9.16644 ms, mean = 7.89869 ms, median = 7.80676 ms, percentile(90%) = 8.35742 ms, percentile(95%) = 8.58826 ms, percentile(99%) = 8.80389 ms
[08/20/2023-11:22:44] [I] GPU Compute Time: min = 16.1608 ms, max = 16.9759 ms, mean = 16.4512 ms, median = 16.384 ms, percentile(90%) = 16.688 ms, percentile(95%) = 16.7957 ms, percentile(99%) = 16.9718 ms
[08/20/2023-11:22:44] [I] D2H Latency: min = 0.0598145 ms, max = 0.0957031 ms, mean = 0.0662092 ms, median = 0.0623779 ms, percentile(90%) = 0.079834 ms, percentile(95%) = 0.0856934 ms, percentile(99%) = 0.0957031 ms
[08/20/2023-11:22:44] [I] Total Host Walltime: 3.06659 s
[08/20/2023-11:22:44] [I] Total GPU Compute Time: 2.05641 s
[08/20/2023-11:22:44] [I] Explanations of the performance metrics are printed in the verbose logs.
[08/20/2023-11:22:44] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8600] # C:\Program Files\TensorRT-8.6.0.12.Windows10.x86_64.cuda-11.8\TensorRT-8.6.0.12\bin\trtexec.exe --onnx=resnet50_bs_dynamic.onnx --saveEngine=demo.engine --minShapes=input:1x3x224x224 --maxShapes=input:128x3x224x224 --optShapes=input:128x3x224x224 --int8
